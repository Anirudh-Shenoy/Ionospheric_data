{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Dataset Selection\n",
        "I am using the Ionosphere dataset from the UCI Machine Learning Repository - https://archive.ics.uci.edu/dataset/52/ionosphere This dataset is for binary classification tasks, as it involves distinguishing between 'good' and 'bad' radar returns. It contains 351 instances with 34 continuous features.\n"
      ],
      "metadata": {
        "id": "7nV_zGjYNiVV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MdgGCU3ONftz",
        "outputId": "7dc33a60-afd0-4d1b-dddf-a25b197b72f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2024.12.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "{'uci_id': 52, 'name': 'Ionosphere', 'repository_url': 'https://archive.ics.uci.edu/dataset/52/ionosphere', 'data_url': 'https://archive.ics.uci.edu/static/public/52/data.csv', 'abstract': 'Classification of radar returns from the ionosphere', 'area': 'Physics and Chemistry', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 351, 'num_features': 34, 'feature_types': ['Integer', 'Real'], 'demographics': [], 'target_col': ['Class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1989, 'last_updated': 'Sun Jan 01 1989', 'dataset_doi': '10.24432/C5W01B', 'creators': ['V. Sigillito', 'S. Wing', 'L. Hutton', 'K. Baker'], 'intro_paper': None, 'additional_info': {'summary': 'This radar data was collected by a system in Goose Bay, Labrador.  This system consists of a phased array of 16 high-frequency antennas with a total transmitted power on the order of 6.4 kilowatts.  See the paper for more details.  The targets were free electrons in the ionosphere. \"Good\" radar returns are those showing evidence of some type of structure in the ionosphere.  \"Bad\" returns are those that do not; their signals pass through the ionosphere.  \\r\\n\\r\\nReceived signals were processed using an autocorrelation function whose arguments are the time of a pulse and the pulse number.  There were 17 pulse numbers for the Goose Bay system.  Instances in this databse are described by 2 attributes per pulse number, corresponding to the complex values returned by the function resulting from the complex electromagnetic signal.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '-- All 34 are continuous\\r\\n-- The 35th attribute is either \"good\" or \"bad\" according to the definition summarized above.  This is a binary classification task.\\r\\n', 'citation': None}}\n",
            "           name     role         type demographic description units  \\\n",
            "0    Attribute1  Feature   Continuous        None        None  None   \n",
            "1    Attribute2  Feature   Continuous        None        None  None   \n",
            "2    Attribute3  Feature   Continuous        None        None  None   \n",
            "3    Attribute4  Feature   Continuous        None        None  None   \n",
            "4    Attribute5  Feature   Continuous        None        None  None   \n",
            "5    Attribute6  Feature   Continuous        None        None  None   \n",
            "6    Attribute7  Feature   Continuous        None        None  None   \n",
            "7    Attribute8  Feature   Continuous        None        None  None   \n",
            "8    Attribute9  Feature   Continuous        None        None  None   \n",
            "9   Attribute10  Feature   Continuous        None        None  None   \n",
            "10  Attribute11  Feature   Continuous        None        None  None   \n",
            "11  Attribute12  Feature   Continuous        None        None  None   \n",
            "12  Attribute13  Feature   Continuous        None        None  None   \n",
            "13  Attribute14  Feature   Continuous        None        None  None   \n",
            "14  Attribute15  Feature   Continuous        None        None  None   \n",
            "15  Attribute16  Feature   Continuous        None        None  None   \n",
            "16  Attribute17  Feature   Continuous        None        None  None   \n",
            "17  Attribute18  Feature   Continuous        None        None  None   \n",
            "18  Attribute19  Feature   Continuous        None        None  None   \n",
            "19  Attribute20  Feature   Continuous        None        None  None   \n",
            "20  Attribute21  Feature   Continuous        None        None  None   \n",
            "21  Attribute22  Feature   Continuous        None        None  None   \n",
            "22  Attribute23  Feature   Continuous        None        None  None   \n",
            "23  Attribute24  Feature   Continuous        None        None  None   \n",
            "24  Attribute25  Feature   Continuous        None        None  None   \n",
            "25  Attribute26  Feature   Continuous        None        None  None   \n",
            "26  Attribute27  Feature   Continuous        None        None  None   \n",
            "27  Attribute28  Feature   Continuous        None        None  None   \n",
            "28  Attribute29  Feature   Continuous        None        None  None   \n",
            "29  Attribute30  Feature   Continuous        None        None  None   \n",
            "30  Attribute31  Feature   Continuous        None        None  None   \n",
            "31  Attribute32  Feature   Continuous        None        None  None   \n",
            "32  Attribute33  Feature   Continuous        None        None  None   \n",
            "33  Attribute34  Feature   Continuous        None        None  None   \n",
            "34        Class   Target  Categorical        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "5              no  \n",
            "6              no  \n",
            "7              no  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11             no  \n",
            "12             no  \n",
            "13             no  \n",
            "14             no  \n",
            "15             no  \n",
            "16             no  \n",
            "17             no  \n",
            "18             no  \n",
            "19             no  \n",
            "20             no  \n",
            "21             no  \n",
            "22             no  \n",
            "23             no  \n",
            "24             no  \n",
            "25             no  \n",
            "26             no  \n",
            "27             no  \n",
            "28             no  \n",
            "29             no  \n",
            "30             no  \n",
            "31             no  \n",
            "32             no  \n",
            "33             no  \n",
            "34             no  \n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "ionosphere = fetch_ucirepo(id=52)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "x = ionosphere.data.features\n",
        "y = ionosphere.data.targets\n",
        "\n",
        "# metadata\n",
        "print(ionosphere.metadata)\n",
        "\n",
        "# variable information\n",
        "print(ionosphere.variables)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Binary Output Variable\n",
        "The Ionosphere dataset already has a binary output variable with classes 'good' and 'bad'. I am mapping these to numerical values: 'good' is 1 and 'bad' is 0\n"
      ],
      "metadata": {
        "id": "Us0fKL1wOA-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Data Transformation\n",
        "\n",
        "Missing Values: The dataset doesn't contain missing values, so no transformation is necessary."
      ],
      "metadata": {
        "id": "5R8KjxjGOIlX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Business Scenario\n",
        "\n",
        "Let's say for example if we're working with a space agency monitoring ionospheric conditions using radar systems then accurately classifying radar returns as 'good' or 'bad' is crucial for determining ionospheric stability, which impacts satellite communications and navigation systems. Timely identification of 'bad' conditions allows for preventive measures, ensuring uninterrupted services."
      ],
      "metadata": {
        "id": "Vn08goMpQRjO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: False Positives and False Negatives\n",
        "\n",
        "In this context:\n",
        "\n",
        "False Positive (FP): Classifying a 'bad' radar return as 'good'. This could lead to undetected ionospheric disturbances, potentially disrupting satellite operations.\n",
        "\n",
        "False Negative (FN): Classifying a 'good' radar return as 'bad'. This might result in unnecessary preventive actions, leading to operational inefficiencies.\n",
        "\n",
        "Given the potential high costs associated with satellite disruptions, false positives are costlier than false negatives. I would assign a cost ratio of 4:1 for FP to FN, reflecting the higher impact of false positives.\n",
        "\n",
        "This is because we would be better off predicting a failure when there was not one as it might only cause a minor disruption, but if we failed to predict a disruption then it would disturb all satelite activities and could result in huge losses."
      ],
      "metadata": {
        "id": "6vXrkP-HZSN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Cost Function\n",
        "\n",
        "Now I will define a function to calculate the total cost based on false positives and false negatives:"
      ],
      "metadata": {
        "id": "UnjuOoHL6A_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_cost(y_actual, y_pred):\n",
        "\n",
        "    fp_cost=6\n",
        "    fn_cost=1\n",
        "    y_actual = np.array(y_actual, dtype=int)\n",
        "    y_pred = np.array(y_pred, dtype=int)\n",
        "    # False Positives: Predicted 1 but actual is 0\n",
        "    FP = sum((y_actual == 0) & (y_pred == 1))\n",
        "\n",
        "    # False Negatives: Predicted 0 but actual is 1\n",
        "    FN = sum((y_actual == 1) & (y_pred == 0))\n",
        "\n",
        "    # Total cost calculation\n",
        "    cost = (fp_cost * FP) + (fn_cost * FN)\n",
        "    return cost\n",
        "\n"
      ],
      "metadata": {
        "id": "_7M-zMZU6D-N"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Threshold Generation\n",
        "\n",
        "Now I generate 100 candidate thresholds evenly spaced between 0 and 1:"
      ],
      "metadata": {
        "id": "Y4vduZ6X6ATf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.linspace(0, 1, 100)\n"
      ],
      "metadata": {
        "id": "4gK13qcj6Nnu"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Cost Matrix Initialization\n",
        "\n",
        "Initialize a 100x10 matrix to store costs for each threshold and fold:"
      ],
      "metadata": {
        "id": "_ZHNwn2l6QMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = np.zeros((100, 10))\n"
      ],
      "metadata": {
        "id": "mRoq6osV6TSF"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Cross-Validation Folds\n",
        "\n",
        "Assign each data point to one of 10 cross-validation folds:"
      ],
      "metadata": {
        "id": "t-amkZPN6UwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ceil(len(y) / 10)\n",
        "fold_vec = np.concatenate([np.arange(1, 11)] * int(n))[:len(y)]\n",
        "np.random.seed(247)\n",
        "fold_vec = np.random.permutation(fold_vec)\n"
      ],
      "metadata": {
        "id": "VKKVk5396XgT"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Logistic Regression and Cost Evaluation\n",
        "\n",
        "Perform logistic regression and evaluate the prediction cost for each threshold using 10-fold cross-validation:"
      ],
      "metadata": {
        "id": "uIL6GENJ6b6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    test_data = np.where(fold_vec == i + 1)\n",
        "    train_data = np.where(fold_vec != i + 1)\n",
        "    label_map = {'g': 1, 'b': 0}\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    x_train = x.iloc[train_data]\n",
        "    y_train = y.iloc[train_data]\n",
        "    x_test = x.iloc[test_data]\n",
        "    y_test = y.iloc[test_data]\n",
        "\n",
        "    # Extract the label column if y_test is a DataFrame\n",
        "    if isinstance(y_test, pd.DataFrame):\n",
        "        y_test = y_test['Class']\n",
        "\n",
        "    # Remove 'Class' and reset index\n",
        "    y_test = y_test[y_test != 'Class']\n",
        "    y_test = y_test.reset_index(drop=True)\n",
        "\n",
        "    # Perform the logistic regression\n",
        "    mod = LogisticRegression(max_iter=1000)\n",
        "    mod.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "    # Predict probabilities\n",
        "    y_pred_prob = mod.predict_proba(x_test)[:, 1]\n",
        "\n",
        "    # Map y_test to numeric labels\n",
        "    y_test = [label_map.get(label, -1) for label in y_test]\n",
        "\n",
        "    # Evaluate predictions\n",
        "    for j, threshold in enumerate(thresholds):\n",
        "        y_pred = [1 if prob >= threshold else 0 for prob in y_pred_prob]\n",
        "        # Uncomment below when calculate_cost is ready\n",
        "        out[j, i] = calculate_cost(y_test, y_pred)\n"
      ],
      "metadata": {
        "id": "1UPaWLu_6bde"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Optimal Threshold Selection\n",
        "\n",
        "Determine the threshold with the lowest average cost across folds:"
      ],
      "metadata": {
        "id": "Y2DPMENY6eRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_costs = out.mean(axis=1)\n",
        "optimal_threshold_index = np.argmin(mean_costs)\n",
        "optimal_threshold = thresholds[optimal_threshold_index]\n",
        "optimal_cost = mean_costs[optimal_threshold_index]\n",
        "\n",
        "print (optimal_cost, optimal_threshold)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "98-Bb3iJ6hj1",
        "outputId": "9b618b76-2dff-4132-e448-5bdd81979073"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15.2 0.8686868686868687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 12: Threshold Refinement\n",
        "\n",
        "Since the threshold is around 0.86 and our cost ratio is 6:1 that would imply that we are much more likely to classify something as positive as opposed to negative, which is inline with our thought process of there being more cost attached to a false positive."
      ],
      "metadata": {
        "id": "OJI5LkG76jG4"
      }
    }
  ]
}